{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final Project_TeamFMA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrmids/fma-predictions/blob/Python-Code-Dev/Final_Project_TeamFMA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9-rWFKfK6X-"
      },
      "source": [
        "# [`IT Experience November Python: Final Project`](https://github.com/mrmids/fma-predictions \"Project GitHub Repository\")\r\n",
        "\r\n",
        "_Collaborators: Midowa Gbededo & Lucky Omenihu_\r\n",
        "\r\n",
        "### **Project Overview**\r\n",
        "[`IT Experience`](https://itexperience.org/ \"IT Experience Website\") organized a free Python class in November, 2020 and as part of the class completion a final project was assigned. Teams were encouraged to work on open source machine learning datasets.\r\n",
        "\r\n",
        "Our team - \"TEAM-FMA\", chose to work on the [`Free Music Archive (FMA) dataset`](https://github.com/mdeff/fma \"FMA Github Repository\") which is a dataset for [`Music Information Retrieval (MIR)`](https://musicinformationretrieval.com/why_mir.html \"About MIR\") and digital music analysis.\r\n",
        "\r\n",
        "This dataset has been analyzed by the original creators of the idea and there exists ample information on analyzing this dataset on their Github repository. \r\n",
        "\r\n",
        "_Many of the comments in this notebook are quotations lifted directly from the information page of the original FMA team. All such comments will be recognized with traditional quotation marks \" \"_\r\n",
        "\r\n",
        "For more information about the original FMA project, please consult:\r\n",
        "1. [`FMA's academic paper`](https://arxiv.org/abs/1612.01840 \"Paper\")\r\n",
        "2. [`FMA's UCI Machine Learning Repository`](https://archive.ics.uci.edu/ml/datasets/FMA%3A+A+Dataset+For+Music+Analysis \"UCI Repository\")\r\n",
        "\r\n",
        "##### **Data Analysis Workflow**\r\n",
        "Our team chose to implent the [`CRoss Industry Standard Process for Data Mining (CRISP-DM)`](https://en.wikipedia.org/wiki/Cross-industry_standard_process_for_data_mining \"CRISP-DM Wikipedia Page\") methodology for our analysis.\r\n",
        "\r\n",
        "\"CRSIP-DM describes the data-mining process in six steps\": [`(citation: Abbott, D, \"Applied Predictive Analytics - Principles and Techniques for the Professional Data Analyst\", pp 19-21, Wiley - 2014)`](https://www.wiley.com/en-us/Applied+Predictive+Analytics%3A+Principles+and+Techniques+for+the+Professional+Data+Analyst-p-9781118727966 \"Wiley Publishers - Book Link\") \r\n",
        "\r\n",
        "|STAGE   |DESCRIPTION|\r\n",
        "|:------|:----------|\r\n",
        "|1. Business Understanding| Define the project|\r\n",
        "|2. Data Understanding| Examine the data; identify problems in the data|\r\n",
        "|3. Data Preparation| Fix problems in the data; create derived variables|\r\n",
        "|4. Modeling| Build predictive or descriptive models|\r\n",
        "|5. Evaluation| Assess models; report on the expected effects of models\r\n",
        "|6. Deployment| Plan for use of models|\r\n",
        "\r\n",
        "What now follows is implementation of the CRISP-DM workflow through the use of the FMA dataset.\r\n",
        "*****"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiTL8vew_7RZ"
      },
      "source": [
        "### **1 - Business Understanding**\r\n",
        "The idea behind this dataset is an effort to utilize machine learning to complete tasks of sorting and organizing large collections of digital music - MP3 files. Some reasons to use machine learning in this way, to name a few, include:\r\n",
        "\r\n",
        "- Sorting large collections of digital music files into genre automatically\r\n",
        "- Identifying the sonic signatures of popular music in different genres\r\n",
        "- Cover song detection, i.e. what songs were produced by sampling other songs? and for given a cover song, identify what song was sampled\r\n",
        "- Recognize the instruments used in songs\r\n",
        "\r\n",
        "Commercial applications of MIR include:\r\n",
        "- Software that teach musical instrument playing, by converting digital music files into easy to play music chords. [`Example - Chordify`](https://chordify.net/ \"Chordify\")\r\n",
        "- Software to auto-tune music samples during music production. [`Example - Melodyne`](https://www.celemony.com/en/start \"Melodyne\")\r\n",
        "- Software to detect musical key of audio samples aiding digital music production. [`Example - iZotope Nectar`](https://www.izotope.com/en/products/nectar.html \"iZotope Nectar\")\r\n",
        "- Apps that identify and name any song playing around you. [`Example - Shazam`](https://www.shazam.com/ \"Shazam\")\r\n",
        "\r\n",
        "\r\n",
        "Refer to the [`MIR Documentation`](https://musicinformationretrieval.com/why_mir.html \"About MIR\") for more information on MIR and it's uses.\r\n",
        "\r\n",
        "*****"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEGH1VvDQXPY"
      },
      "source": [
        "### **Python Packages Used:**\r\n",
        "- [`Librosa:`](https://librosa.org/ \"Librosa\") audio and music processing in python\r\n",
        "- [`Google-Colab:`](https://pypi.org/project/google-colab/ \"Google-Colab\") colaboratory-specific python libraries\r\n",
        "- [`Pandas:`](https://pandas.pydata.org/ \"Pandas\") data analysis and manipulation tool\r\n",
        "- [`NumPy:`](https://numpy.org/ \"NumPy\") scientific computing with Python\r\n",
        "- [`Matplotlib:`](https://matplotlib.org/ \"Matplotlib\") comprehensive library for creating static, animated, and interactive visualizations in Python\r\n",
        "- [`Seaborn:`](https://seaborn.pydata.org/ \"Seaborn\") provides a high-level interface for drawing attractive and informative statistical graphics\r\n",
        "- [`SciKit Learn:`](https://scikit-learn.org/stable/ \"SKLearn\") machine Learning in Python\r\n",
        "- [`Keras:`](https://keras.io/ \"Keras\") high-level neural networks API for Python\r\n",
        "- [`IPython:`](https://ipython.org/ \"IPython\") provides a rich architecture for interactive computing\r\n",
        "- [`CSV:`](https://docs.python.org/3/library/csv.html \"CSV\") module implements classes to read and write tabular data in CSV format [(useful examples)](https://www.programiz.com/python-programming/reading-csv-files)\r\n",
        "- [`Warnings:`](https://docs.python.org/3/library/warnings.html \"Warnings\") provides control of warning message output on notebook screen\r\n",
        "\r\n",
        "*****"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMuLQ_6o_8DM"
      },
      "source": [
        "### **Useful Solution Links For Challenges Ecountered:**\r\n",
        "\r\n",
        "1. _Read CSV file into Colab from Google Drive folder:_ Utilized the drive mount method in the Google-Colab package. [`Loading data into Colab from Google Drive`](https://towardsdatascience.com/3-ways-to-load-csv-files-into-colab-7c14fcbdcb92 \"CSV from Google Drive\")\r\n",
        "2. *Read CSV file with multi-row headers using `pandas.read_csv`:* First solved the multi row header challenge here [`Pandas DataFrame: Playing with CSV files`](https://towardsdatascience.com/pandas-dataframe-playing-with-csv-files-944225d19ff \"CSV Multi-Row Header\"), then tackled renaming rows and column that showed up as \"unnamed\" using the tips from [`Stack Overflow`](https://stackoverflow.com/questions/48059994/mark-empty-values-in-pandas-dataframe-multi-row-header \"Rename dataframe columns\"). A sample from the data developers showing what the proper csv file read should look like is seen in this [`screenshot example`](https://ibb.co/DtWXXqX \"screenshot\")\r\n",
        "3. *Force index of pandas dataframe to be the first column of the CSV file using `pandas.DataFrame.set_index`:* The first resource found for this problem was to use the [`Pandas Set Index`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.set_index.html \"Pandas Set Index\"). Some more help from [`Stackoverflow`](https://stackoverflow.com/questions/38542419/could-pandas-use-column-as-index \"Stackoverflow Index\")\r\n",
        "4. _Hierarchical indexing of pandas dataframe:_ Resource found for this problem was to use the [`Pandas Hierarchical indexing`](https://pandas.pydata.org/pandas-docs/stable/user_guide/advanced.html \"Pandas Hierarchical indexing\")\r\n",
        "\r\n",
        "*****"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkTMkapvtxYk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81cddc1a-4b5a-4ca4-9924-e9e84ee50a42"
      },
      "source": [
        "## Connect to Google Drive\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lN2eg_ZMZD0k"
      },
      "source": [
        "## Import the necessary library packages\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn as skl\n",
        "import sklearn.utils, sklearn.preprocessing, sklearn.decomposition, sklearn.svm\n",
        "import librosa\n",
        "import librosa.display\n",
        "import os\n",
        "import IPython.display as ipd\n",
        "import csv\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#warnings.filterwarnings(action='once')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hm9bNMufdA0M"
      },
      "source": [
        "## Identify folder holding mp3 files ** Change path to how it appears on your google drive\r\n",
        "\r\n",
        "path_audio_dir = \"/content/drive/MyDrive/Colab Notebooks/ITExperience Python Training/Final Project/fma_small\"\r\n",
        "\r\n",
        "audio_dir = os.environ.get(path_audio_dir)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvV-1k3uvT_e"
      },
      "source": [
        "## Load the url paths from Google Drive for the FMA MetaData Data Files ** Change path to how it appears on your google drive\r\n",
        "\r\n",
        "path_echonest = \"/content/drive/MyDrive/Colab Notebooks/ITExperience Python Training/Final Project/fma_metadata/echonest.csv\"\r\n",
        "path_tracks = \"/content/drive/MyDrive/Colab Notebooks/ITExperience Python Training/Final Project/fma_metadata/tracks.csv\"\r\n",
        "path_features = \"/content/drive/MyDrive/Colab Notebooks/ITExperience Python Training/Final Project/fma_metadata/features.csv\"\r\n",
        "path_genres = \"/content/drive/MyDrive/Colab Notebooks/ITExperience Python Training/Final Project/fma_metadata/genres.csv\"\r\n",
        "\r\n",
        "#echonest = pd.read_csv(path_echonest)\r\n",
        "#tracks = pd.read_csv(path_tracks)\r\n",
        "#features = pd.read_csv(path_features)\r\n",
        "#genres = pd.read_csv(path_genres)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRAoHdSX3hLK"
      },
      "source": [
        "# Load the Echonest data, taking care of the multiple header rows\r\n",
        "# \"The Echonest file contains audio features provided by Echonest for a subset of 13,129 tracks\"\r\n",
        "\r\n",
        "# This step contains some data preparation in form of manipulating the multi-row header\r\n",
        "\r\n",
        "echonest = pd.read_csv(path_echonest,  header = [0,1,2,3], na_values=[-1,''])\r\n",
        "\r\n",
        "a = echonest.columns.get_level_values(level=0).str.replace('Un.*','')\r\n",
        "b = echonest.columns.get_level_values(level=1).str.replace('Un.*','')\r\n",
        "c = echonest.columns.get_level_values(level=2).str.replace('Un.*','')\r\n",
        "d = echonest.columns.get_level_values(level=3).str.replace('Un.*','')\r\n",
        "\r\n",
        "echonest.columns = [a, b, c, d]\r\n",
        "\r\n",
        "## The next set of commented lines of code are codes that could come in handy\r\n",
        "\r\n",
        "#echonest.set_index([('', '', '', 'track_id')], inplace=True)\r\n",
        "#echonest = echonest.rename_axis(\"track_id\")\r\n",
        "\r\n",
        "#list(echonest.columns.values.tolist())\r\n",
        "#echonest.columns.levels\r\n",
        "#echonest.set_index([('', '', '', 'track_id')])\r\n",
        "\r\n",
        "#new_index = echonest[('', '', '', 'track_id')]\r\n",
        "\r\n",
        "#echonest.reindex(new_index)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zw1jRJk38oBi"
      },
      "source": [
        "# Load the Tracks data, taking care of the multiple header rows\r\n",
        "# \"Tracks data contains per track metadata such as ID, title, artist, genres, tags and play counts, for all 106,574 tracks\"\r\n",
        "\r\n",
        "# This step contains some data preparation in form of manipulating the multi-row header\r\n",
        "\r\n",
        "tracks = pd.read_csv(path_tracks, header = [0,1,2], na_values=[-1,''])\r\n",
        "\r\n",
        "a = tracks.columns.get_level_values(level=0).str.replace('Un.*','')\r\n",
        "b = tracks.columns.get_level_values(level=1).str.replace('Un.*','')\r\n",
        "c = tracks.columns.get_level_values(level=2).str.replace('Un.*','')\r\n",
        "\r\n",
        "tracks.columns = [a, b, c]\r\n",
        "\r\n",
        "#tracks.set_index([('', '', 'track_id')], inplace=True)\r\n",
        "#tracks = tracks.rename_axis(\"track_id\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUhOo0Nf95bX"
      },
      "source": [
        "# Load the Feature data, taking care of the multiple header rows\r\n",
        "# \"Features data contains per track common features extracted with librosa, for all 106,574 tracks\"\r\n",
        "\r\n",
        "# This step contains some data preparation in form of manipulating the multi-row header\r\n",
        "\r\n",
        "features = pd.read_csv(path_features, index_col=0, header = [0,1,2,3], na_values=[-1,''])\r\n",
        "\r\n",
        "a = features.columns.get_level_values(level=0).str.replace('Un.*','')\r\n",
        "b = features.columns.get_level_values(level=1).str.replace('Un.*','')\r\n",
        "c = features.columns.get_level_values(level=2).str.replace('Un.*','')\r\n",
        "d = features.columns.get_level_values(level=3).str.replace('Un.*','')\r\n",
        "\r\n",
        "features.columns = [a, b, c, d]\r\n",
        "\r\n",
        "#features.set_index([('feature', 'statistics', 'number', 'track_id')], inplace=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rnmb-fO86eQw"
      },
      "source": [
        "# Load the Genres data, it has a single row header and is a straight forward load\n",
        "# \"Genre data contains all 163 genres with name and parent (used to infer the genre hierarchy and top-level genres)\"\n",
        "\n",
        "genres = pd.read_csv(path_genres)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tqf9CV_w4E7"
      },
      "source": [
        "*****\r\n",
        "### **2 - Data Understanding**\r\n",
        "\r\n",
        "Three of the four CSV files contained in the fma_metadata folder have multi-row headers. This means that the dataframes can be referenced at multiple levels and each dataframe can be sliced up in smaller sub-sections for analysis.\r\n",
        "\r\n",
        "Dataframe column levels and column name lists are used to inspect the dataframes. Sample code used to do this is as follows:\r\n",
        "\r\n",
        "    #To check the column levels\r\n",
        "    echonest.columns.levels\r\n",
        "\r\n",
        "    #To check the column names\r\n",
        "    list(echonest.columns.values.tolist())\r\n",
        "\r\n",
        "##### **2.1 - Check For Data Consitency**\r\n",
        "\r\n",
        "Check that the row counts and relational key between tables, in our case the \"track_id\" column, are all consistent\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_h730dys0UV"
      },
      "source": [
        "# Checking for data consistency using assert condition\r\n",
        "# Conditions that need to be satisfied are:\r\n",
        "# 1. Features dataframe needs to be the sasme size as the tracks dataframe. \r\n",
        "#     The features dataframe represent sonic signatures extracted from every song in the track folder\r\n",
        "#     The tracks dataframe\r\n",
        "# 2. The track IDs  in the echonest dataset are also contained in the tracks and features files\r\n",
        "# assert works by not returning any errors. If false, then there is an error\r\n",
        "\r\n",
        "np.testing.assert_array_equal(features.index, tracks.index)\r\n",
        "assert echonest.index.isin(tracks.index).all()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3pXqDPTLSlo"
      },
      "source": [
        "##### **2.2 - The Tracks Dataset**\r\n",
        "\r\n",
        "\"Tracks data contains per track metadata such as ID, title, artist, genres, tags and play counts, for all 106,574 tracks\"\r\n",
        "\r\n",
        "Using basic print and dataframe functions to inspect the tracks dataset, it is "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncTIvqxCLBay",
        "outputId": "96563584-4571-43b5-db6d-c21e61bfd9d4"
      },
      "source": [
        "# Summary of tracks and genre datasets\r\n",
        "print('{} tracks, {} artists, {} albums, {} genres'.format(\r\n",
        "    len(tracks), len(tracks['artist', 'id'].unique()),\r\n",
        "    len(tracks['album', 'id'].unique()),\r\n",
        "    sum(genres['#tracks'] > 0)))\r\n",
        "mean_duration = tracks['track', 'duration'].mean()\r\n",
        "print('track duration: {:.0f} days total, {:.0f} seconds average'.format(\r\n",
        "    sum(tracks['track', 'duration']) / 3600 / 24,\r\n",
        "    mean_duration))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "106574 tracks, 16341 artists, 14854 albums, 161 genres\n",
            "track duration: 343 days total, 278 seconds average\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tKlq8QH21lK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGDToVMJ08gO"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffIFoi_V_Toe"
      },
      "source": [
        "##### **2.3 - The Echonest Dataset**\r\n",
        "\r\n",
        "\"The Echonest file contains audio features provided by Echonest for a subset of 13,129 tracks\"\r\n",
        "\r\n",
        "Utilize basic print and dataframe functions to inspect what is inside the Echonest dataset.\r\n",
        "\r\n",
        "It is seen that the Echonest dataset is comprised of the following multi-level hierrarchy for **each track**:\r\n",
        "\r\n",
        "1. _Audio features:_ acousticness, danceability, energy, liveliness, tempo etc.\r\n",
        "2. _Track Metadata:_ album name, date, artist, artist geographic location etc.\r\n",
        "3. _Track Music Charts Ranking:_ artist popularity, familiarity, song hotness etc.\r\n",
        "4. _Track Social Features:_ measures of artist based on social parameters - artist hotness\r\n",
        "5. _Temporal Features:_ Represents 223 different properties used to classify each track"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "1QYXWL2R0dZv",
        "outputId": "0ecc8af0-2dea-4aa4-e89a-9c6197281051"
      },
      "source": [
        "echonest.head()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th colspan=\"80\" halign=\"left\">echonest</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th colspan=\"8\" halign=\"left\">audio_features</th>\n",
              "      <th colspan=\"7\" halign=\"left\">metadata</th>\n",
              "      <th colspan=\"5\" halign=\"left\">ranks</th>\n",
              "      <th colspan=\"5\" halign=\"left\">social_features</th>\n",
              "      <th colspan=\"55\" halign=\"left\">temporal_features</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>acousticness</th>\n",
              "      <th>danceability</th>\n",
              "      <th>energy</th>\n",
              "      <th>instrumentalness</th>\n",
              "      <th>liveness</th>\n",
              "      <th>speechiness</th>\n",
              "      <th>tempo</th>\n",
              "      <th>valence</th>\n",
              "      <th>album_date</th>\n",
              "      <th>album_name</th>\n",
              "      <th>artist_latitude</th>\n",
              "      <th>artist_location</th>\n",
              "      <th>artist_longitude</th>\n",
              "      <th>artist_name</th>\n",
              "      <th>release</th>\n",
              "      <th>artist_discovery_rank</th>\n",
              "      <th>artist_familiarity_rank</th>\n",
              "      <th>artist_hotttnesss_rank</th>\n",
              "      <th>song_currency_rank</th>\n",
              "      <th>song_hotttnesss_rank</th>\n",
              "      <th>artist_discovery</th>\n",
              "      <th>artist_familiarity</th>\n",
              "      <th>artist_hotttnesss</th>\n",
              "      <th>song_currency</th>\n",
              "      <th>song_hotttnesss</th>\n",
              "      <th>000</th>\n",
              "      <th>001</th>\n",
              "      <th>002</th>\n",
              "      <th>003</th>\n",
              "      <th>004</th>\n",
              "      <th>005</th>\n",
              "      <th>006</th>\n",
              "      <th>007</th>\n",
              "      <th>008</th>\n",
              "      <th>009</th>\n",
              "      <th>010</th>\n",
              "      <th>011</th>\n",
              "      <th>012</th>\n",
              "      <th>013</th>\n",
              "      <th>...</th>\n",
              "      <th>184</th>\n",
              "      <th>185</th>\n",
              "      <th>186</th>\n",
              "      <th>187</th>\n",
              "      <th>188</th>\n",
              "      <th>189</th>\n",
              "      <th>190</th>\n",
              "      <th>191</th>\n",
              "      <th>192</th>\n",
              "      <th>193</th>\n",
              "      <th>194</th>\n",
              "      <th>195</th>\n",
              "      <th>196</th>\n",
              "      <th>197</th>\n",
              "      <th>198</th>\n",
              "      <th>199</th>\n",
              "      <th>200</th>\n",
              "      <th>201</th>\n",
              "      <th>202</th>\n",
              "      <th>203</th>\n",
              "      <th>204</th>\n",
              "      <th>205</th>\n",
              "      <th>206</th>\n",
              "      <th>207</th>\n",
              "      <th>208</th>\n",
              "      <th>209</th>\n",
              "      <th>210</th>\n",
              "      <th>211</th>\n",
              "      <th>212</th>\n",
              "      <th>213</th>\n",
              "      <th>214</th>\n",
              "      <th>215</th>\n",
              "      <th>216</th>\n",
              "      <th>217</th>\n",
              "      <th>218</th>\n",
              "      <th>219</th>\n",
              "      <th>220</th>\n",
              "      <th>221</th>\n",
              "      <th>222</th>\n",
              "      <th>223</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>track_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>...</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>0.416675</td>\n",
              "      <td>0.675894</td>\n",
              "      <td>0.634476</td>\n",
              "      <td>0.010628</td>\n",
              "      <td>0.177647</td>\n",
              "      <td>0.159310</td>\n",
              "      <td>165.922</td>\n",
              "      <td>0.576661</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>32.6783</td>\n",
              "      <td>Georgia, US</td>\n",
              "      <td>-83.2230</td>\n",
              "      <td>AWOL</td>\n",
              "      <td>AWOL - A Way Of Life</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.388990</td>\n",
              "      <td>0.386740</td>\n",
              "      <td>0.406370</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.877233</td>\n",
              "      <td>0.588911</td>\n",
              "      <td>0.354243</td>\n",
              "      <td>0.295090</td>\n",
              "      <td>0.298413</td>\n",
              "      <td>0.309430</td>\n",
              "      <td>0.304496</td>\n",
              "      <td>0.334579</td>\n",
              "      <td>0.249495</td>\n",
              "      <td>0.259656</td>\n",
              "      <td>0.318376</td>\n",
              "      <td>0.371974</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.5710</td>\n",
              "      <td>...</td>\n",
              "      <td>0.097149</td>\n",
              "      <td>0.401260</td>\n",
              "      <td>0.006324</td>\n",
              "      <td>0.643486</td>\n",
              "      <td>0.012059</td>\n",
              "      <td>0.237947</td>\n",
              "      <td>0.655938</td>\n",
              "      <td>1.213864</td>\n",
              "      <td>-12.486146</td>\n",
              "      <td>-11.2695</td>\n",
              "      <td>46.031261</td>\n",
              "      <td>-60.000000</td>\n",
              "      <td>-3.933</td>\n",
              "      <td>56.067001</td>\n",
              "      <td>-2.587475</td>\n",
              "      <td>11.802585</td>\n",
              "      <td>0.047970</td>\n",
              "      <td>0.038275</td>\n",
              "      <td>0.000988</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.20730</td>\n",
              "      <td>0.20730</td>\n",
              "      <td>1.603659</td>\n",
              "      <td>2.984276</td>\n",
              "      <td>-21.812077</td>\n",
              "      <td>-20.312000</td>\n",
              "      <td>49.157482</td>\n",
              "      <td>-60.0</td>\n",
              "      <td>-9.691</td>\n",
              "      <td>50.308998</td>\n",
              "      <td>-1.992303</td>\n",
              "      <td>6.805694</td>\n",
              "      <td>0.233070</td>\n",
              "      <td>0.192880</td>\n",
              "      <td>0.027455</td>\n",
              "      <td>0.06408</td>\n",
              "      <td>3.67696</td>\n",
              "      <td>3.61288</td>\n",
              "      <td>13.316690</td>\n",
              "      <td>262.929749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>0.374408</td>\n",
              "      <td>0.528643</td>\n",
              "      <td>0.817461</td>\n",
              "      <td>0.001851</td>\n",
              "      <td>0.105880</td>\n",
              "      <td>0.461818</td>\n",
              "      <td>126.957</td>\n",
              "      <td>0.269240</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>32.6783</td>\n",
              "      <td>Georgia, US</td>\n",
              "      <td>-83.2230</td>\n",
              "      <td>AWOL</td>\n",
              "      <td>AWOL - A Way Of Life</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.388990</td>\n",
              "      <td>0.386740</td>\n",
              "      <td>0.406370</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.534429</td>\n",
              "      <td>0.537414</td>\n",
              "      <td>0.443299</td>\n",
              "      <td>0.390879</td>\n",
              "      <td>0.344573</td>\n",
              "      <td>0.366448</td>\n",
              "      <td>0.419455</td>\n",
              "      <td>0.747766</td>\n",
              "      <td>0.460901</td>\n",
              "      <td>0.392379</td>\n",
              "      <td>0.474559</td>\n",
              "      <td>0.406729</td>\n",
              "      <td>0.506</td>\n",
              "      <td>0.5145</td>\n",
              "      <td>...</td>\n",
              "      <td>1.015813</td>\n",
              "      <td>1.627731</td>\n",
              "      <td>0.032318</td>\n",
              "      <td>0.819126</td>\n",
              "      <td>-0.030998</td>\n",
              "      <td>0.734610</td>\n",
              "      <td>0.458883</td>\n",
              "      <td>0.999964</td>\n",
              "      <td>-12.502044</td>\n",
              "      <td>-11.4205</td>\n",
              "      <td>26.468552</td>\n",
              "      <td>-60.000000</td>\n",
              "      <td>-5.789</td>\n",
              "      <td>54.210999</td>\n",
              "      <td>-1.755855</td>\n",
              "      <td>7.895351</td>\n",
              "      <td>0.057707</td>\n",
              "      <td>0.045360</td>\n",
              "      <td>0.001397</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.33950</td>\n",
              "      <td>0.33950</td>\n",
              "      <td>2.271021</td>\n",
              "      <td>9.186051</td>\n",
              "      <td>-20.185032</td>\n",
              "      <td>-19.868000</td>\n",
              "      <td>24.002327</td>\n",
              "      <td>-60.0</td>\n",
              "      <td>-9.679</td>\n",
              "      <td>50.320999</td>\n",
              "      <td>-1.582331</td>\n",
              "      <td>8.889308</td>\n",
              "      <td>0.258464</td>\n",
              "      <td>0.220905</td>\n",
              "      <td>0.081368</td>\n",
              "      <td>0.06413</td>\n",
              "      <td>6.08277</td>\n",
              "      <td>6.01864</td>\n",
              "      <td>16.673548</td>\n",
              "      <td>325.581085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>0.043567</td>\n",
              "      <td>0.745566</td>\n",
              "      <td>0.701470</td>\n",
              "      <td>0.000697</td>\n",
              "      <td>0.373143</td>\n",
              "      <td>0.124595</td>\n",
              "      <td>100.260</td>\n",
              "      <td>0.621661</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>32.6783</td>\n",
              "      <td>Georgia, US</td>\n",
              "      <td>-83.2230</td>\n",
              "      <td>AWOL</td>\n",
              "      <td>AWOL - A Way Of Life</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.388990</td>\n",
              "      <td>0.386740</td>\n",
              "      <td>0.406370</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.548093</td>\n",
              "      <td>0.720192</td>\n",
              "      <td>0.389257</td>\n",
              "      <td>0.344934</td>\n",
              "      <td>0.361300</td>\n",
              "      <td>0.402543</td>\n",
              "      <td>0.434044</td>\n",
              "      <td>0.388137</td>\n",
              "      <td>0.512487</td>\n",
              "      <td>0.525755</td>\n",
              "      <td>0.425371</td>\n",
              "      <td>0.446896</td>\n",
              "      <td>0.511</td>\n",
              "      <td>0.7720</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.250734</td>\n",
              "      <td>4.719755</td>\n",
              "      <td>-0.183342</td>\n",
              "      <td>0.340812</td>\n",
              "      <td>-0.295970</td>\n",
              "      <td>0.099103</td>\n",
              "      <td>0.098723</td>\n",
              "      <td>1.389372</td>\n",
              "      <td>-15.458095</td>\n",
              "      <td>-14.1050</td>\n",
              "      <td>35.955223</td>\n",
              "      <td>-60.000000</td>\n",
              "      <td>-7.248</td>\n",
              "      <td>52.751999</td>\n",
              "      <td>-2.505533</td>\n",
              "      <td>9.716598</td>\n",
              "      <td>0.058608</td>\n",
              "      <td>0.045700</td>\n",
              "      <td>0.001777</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.29497</td>\n",
              "      <td>0.29497</td>\n",
              "      <td>1.827837</td>\n",
              "      <td>5.253727</td>\n",
              "      <td>-24.523119</td>\n",
              "      <td>-24.367001</td>\n",
              "      <td>31.804546</td>\n",
              "      <td>-60.0</td>\n",
              "      <td>-12.582</td>\n",
              "      <td>47.417999</td>\n",
              "      <td>-2.288358</td>\n",
              "      <td>11.527109</td>\n",
              "      <td>0.256821</td>\n",
              "      <td>0.237820</td>\n",
              "      <td>0.060122</td>\n",
              "      <td>0.06014</td>\n",
              "      <td>5.92649</td>\n",
              "      <td>5.86635</td>\n",
              "      <td>16.013849</td>\n",
              "      <td>356.755737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10</td>\n",
              "      <td>0.951670</td>\n",
              "      <td>0.658179</td>\n",
              "      <td>0.924525</td>\n",
              "      <td>0.965427</td>\n",
              "      <td>0.115474</td>\n",
              "      <td>0.032985</td>\n",
              "      <td>111.562</td>\n",
              "      <td>0.963590</td>\n",
              "      <td>2008-03-11</td>\n",
              "      <td>Constant Hitmaker</td>\n",
              "      <td>39.9523</td>\n",
              "      <td>Philadelphia, PA, US</td>\n",
              "      <td>-75.1624</td>\n",
              "      <td>Kurt Vile</td>\n",
              "      <td>Constant Hitmaker</td>\n",
              "      <td>2635.0</td>\n",
              "      <td>2544.0</td>\n",
              "      <td>397.0</td>\n",
              "      <td>115691.0</td>\n",
              "      <td>67609.0</td>\n",
              "      <td>0.557339</td>\n",
              "      <td>0.614272</td>\n",
              "      <td>0.798387</td>\n",
              "      <td>0.005158</td>\n",
              "      <td>0.354516</td>\n",
              "      <td>0.311404</td>\n",
              "      <td>0.711402</td>\n",
              "      <td>0.321914</td>\n",
              "      <td>0.500601</td>\n",
              "      <td>0.250963</td>\n",
              "      <td>0.321316</td>\n",
              "      <td>0.734250</td>\n",
              "      <td>0.325188</td>\n",
              "      <td>0.373012</td>\n",
              "      <td>0.235840</td>\n",
              "      <td>0.368756</td>\n",
              "      <td>0.440775</td>\n",
              "      <td>0.263</td>\n",
              "      <td>0.7360</td>\n",
              "      <td>...</td>\n",
              "      <td>7.889378</td>\n",
              "      <td>1.809147</td>\n",
              "      <td>2.219095</td>\n",
              "      <td>1.518430</td>\n",
              "      <td>0.654815</td>\n",
              "      <td>0.650727</td>\n",
              "      <td>12.656473</td>\n",
              "      <td>0.406731</td>\n",
              "      <td>-10.244890</td>\n",
              "      <td>-9.4640</td>\n",
              "      <td>20.304308</td>\n",
              "      <td>-60.000000</td>\n",
              "      <td>-5.027</td>\n",
              "      <td>54.973000</td>\n",
              "      <td>-5.365219</td>\n",
              "      <td>41.201279</td>\n",
              "      <td>0.048938</td>\n",
              "      <td>0.040800</td>\n",
              "      <td>0.002591</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.89574</td>\n",
              "      <td>0.89574</td>\n",
              "      <td>10.539709</td>\n",
              "      <td>150.359985</td>\n",
              "      <td>-16.472773</td>\n",
              "      <td>-15.903000</td>\n",
              "      <td>27.539440</td>\n",
              "      <td>-60.0</td>\n",
              "      <td>-9.025</td>\n",
              "      <td>50.974998</td>\n",
              "      <td>-3.662988</td>\n",
              "      <td>21.508228</td>\n",
              "      <td>0.283352</td>\n",
              "      <td>0.267070</td>\n",
              "      <td>0.125704</td>\n",
              "      <td>0.08082</td>\n",
              "      <td>8.41401</td>\n",
              "      <td>8.33319</td>\n",
              "      <td>21.317064</td>\n",
              "      <td>483.403809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>134</td>\n",
              "      <td>0.452217</td>\n",
              "      <td>0.513238</td>\n",
              "      <td>0.560410</td>\n",
              "      <td>0.019443</td>\n",
              "      <td>0.096567</td>\n",
              "      <td>0.525519</td>\n",
              "      <td>114.290</td>\n",
              "      <td>0.894072</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>32.6783</td>\n",
              "      <td>Georgia, US</td>\n",
              "      <td>-83.2230</td>\n",
              "      <td>AWOL</td>\n",
              "      <td>AWOL - A Way Of Life</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.388990</td>\n",
              "      <td>0.386740</td>\n",
              "      <td>0.406370</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.610849</td>\n",
              "      <td>0.569169</td>\n",
              "      <td>0.428494</td>\n",
              "      <td>0.345796</td>\n",
              "      <td>0.376920</td>\n",
              "      <td>0.460590</td>\n",
              "      <td>0.401371</td>\n",
              "      <td>0.449900</td>\n",
              "      <td>0.428946</td>\n",
              "      <td>0.446736</td>\n",
              "      <td>0.479849</td>\n",
              "      <td>0.378221</td>\n",
              "      <td>0.614</td>\n",
              "      <td>0.5450</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.139364</td>\n",
              "      <td>2.251030</td>\n",
              "      <td>-0.224826</td>\n",
              "      <td>0.050703</td>\n",
              "      <td>0.188019</td>\n",
              "      <td>0.249750</td>\n",
              "      <td>0.931698</td>\n",
              "      <td>0.766069</td>\n",
              "      <td>-15.145472</td>\n",
              "      <td>-14.1510</td>\n",
              "      <td>19.988146</td>\n",
              "      <td>-40.209999</td>\n",
              "      <td>-7.351</td>\n",
              "      <td>32.859001</td>\n",
              "      <td>-1.632508</td>\n",
              "      <td>3.340982</td>\n",
              "      <td>0.059470</td>\n",
              "      <td>0.048560</td>\n",
              "      <td>0.001586</td>\n",
              "      <td>0.01079</td>\n",
              "      <td>0.42006</td>\n",
              "      <td>0.40927</td>\n",
              "      <td>2.763948</td>\n",
              "      <td>13.718324</td>\n",
              "      <td>-24.336575</td>\n",
              "      <td>-22.448999</td>\n",
              "      <td>52.783905</td>\n",
              "      <td>-60.0</td>\n",
              "      <td>-13.128</td>\n",
              "      <td>46.872002</td>\n",
              "      <td>-1.452696</td>\n",
              "      <td>2.356398</td>\n",
              "      <td>0.234686</td>\n",
              "      <td>0.199550</td>\n",
              "      <td>0.149332</td>\n",
              "      <td>0.06440</td>\n",
              "      <td>11.26707</td>\n",
              "      <td>11.20267</td>\n",
              "      <td>26.454180</td>\n",
              "      <td>751.147705</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 250 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 echonest               ...                                         \n",
              "           audio_features               ... temporal_features                       \n",
              "             acousticness danceability  ...               221        222         223\n",
              "  track_id                              ...                                         \n",
              "0        2       0.416675     0.675894  ...           3.61288  13.316690  262.929749\n",
              "1        3       0.374408     0.528643  ...           6.01864  16.673548  325.581085\n",
              "2        5       0.043567     0.745566  ...           5.86635  16.013849  356.755737\n",
              "3       10       0.951670     0.658179  ...           8.33319  21.317064  483.403809\n",
              "4      134       0.452217     0.513238  ...          11.20267  26.454180  751.147705\n",
              "\n",
              "[5 rows x 250 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWO5t8LfKw1J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 838
        },
        "outputId": "26478eec-af6d-461a-eab9-98ab6c6b5f77"
      },
      "source": [
        "print('{1} features for {0} tracks'.format(*echonest.shape))\r\n",
        "ipd.display(echonest['echonest', 'metadata'].head())\r\n",
        "ipd.display(echonest['echonest', 'audio_features'].head())\r\n",
        "ipd.display(echonest['echonest', 'social_features'].head())\r\n",
        "ipd.display(echonest['echonest', 'ranks'].head())"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "250 features for 13129 tracks\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>album_date</th>\n",
              "      <th>album_name</th>\n",
              "      <th>artist_latitude</th>\n",
              "      <th>artist_location</th>\n",
              "      <th>artist_longitude</th>\n",
              "      <th>artist_name</th>\n",
              "      <th>release</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>32.6783</td>\n",
              "      <td>Georgia, US</td>\n",
              "      <td>-83.2230</td>\n",
              "      <td>AWOL</td>\n",
              "      <td>AWOL - A Way Of Life</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>32.6783</td>\n",
              "      <td>Georgia, US</td>\n",
              "      <td>-83.2230</td>\n",
              "      <td>AWOL</td>\n",
              "      <td>AWOL - A Way Of Life</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>32.6783</td>\n",
              "      <td>Georgia, US</td>\n",
              "      <td>-83.2230</td>\n",
              "      <td>AWOL</td>\n",
              "      <td>AWOL - A Way Of Life</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2008-03-11</td>\n",
              "      <td>Constant Hitmaker</td>\n",
              "      <td>39.9523</td>\n",
              "      <td>Philadelphia, PA, US</td>\n",
              "      <td>-75.1624</td>\n",
              "      <td>Kurt Vile</td>\n",
              "      <td>Constant Hitmaker</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>32.6783</td>\n",
              "      <td>Georgia, US</td>\n",
              "      <td>-83.2230</td>\n",
              "      <td>AWOL</td>\n",
              "      <td>AWOL - A Way Of Life</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   album_date         album_name  ... artist_name               release\n",
              "                                  ...                                  \n",
              "0         NaN                NaN  ...        AWOL  AWOL - A Way Of Life\n",
              "1         NaN                NaN  ...        AWOL  AWOL - A Way Of Life\n",
              "2         NaN                NaN  ...        AWOL  AWOL - A Way Of Life\n",
              "3  2008-03-11  Constant Hitmaker  ...   Kurt Vile     Constant Hitmaker\n",
              "4         NaN                NaN  ...        AWOL  AWOL - A Way Of Life\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>acousticness</th>\n",
              "      <th>danceability</th>\n",
              "      <th>energy</th>\n",
              "      <th>instrumentalness</th>\n",
              "      <th>liveness</th>\n",
              "      <th>speechiness</th>\n",
              "      <th>tempo</th>\n",
              "      <th>valence</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.416675</td>\n",
              "      <td>0.675894</td>\n",
              "      <td>0.634476</td>\n",
              "      <td>0.010628</td>\n",
              "      <td>0.177647</td>\n",
              "      <td>0.159310</td>\n",
              "      <td>165.922</td>\n",
              "      <td>0.576661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.374408</td>\n",
              "      <td>0.528643</td>\n",
              "      <td>0.817461</td>\n",
              "      <td>0.001851</td>\n",
              "      <td>0.105880</td>\n",
              "      <td>0.461818</td>\n",
              "      <td>126.957</td>\n",
              "      <td>0.269240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.043567</td>\n",
              "      <td>0.745566</td>\n",
              "      <td>0.701470</td>\n",
              "      <td>0.000697</td>\n",
              "      <td>0.373143</td>\n",
              "      <td>0.124595</td>\n",
              "      <td>100.260</td>\n",
              "      <td>0.621661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.951670</td>\n",
              "      <td>0.658179</td>\n",
              "      <td>0.924525</td>\n",
              "      <td>0.965427</td>\n",
              "      <td>0.115474</td>\n",
              "      <td>0.032985</td>\n",
              "      <td>111.562</td>\n",
              "      <td>0.963590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.452217</td>\n",
              "      <td>0.513238</td>\n",
              "      <td>0.560410</td>\n",
              "      <td>0.019443</td>\n",
              "      <td>0.096567</td>\n",
              "      <td>0.525519</td>\n",
              "      <td>114.290</td>\n",
              "      <td>0.894072</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  acousticness danceability    energy  ... speechiness    tempo   valence\n",
              "                                       ...                               \n",
              "0     0.416675     0.675894  0.634476  ...    0.159310  165.922  0.576661\n",
              "1     0.374408     0.528643  0.817461  ...    0.461818  126.957  0.269240\n",
              "2     0.043567     0.745566  0.701470  ...    0.124595  100.260  0.621661\n",
              "3     0.951670     0.658179  0.924525  ...    0.032985  111.562  0.963590\n",
              "4     0.452217     0.513238  0.560410  ...    0.525519  114.290  0.894072\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>artist_discovery</th>\n",
              "      <th>artist_familiarity</th>\n",
              "      <th>artist_hotttnesss</th>\n",
              "      <th>song_currency</th>\n",
              "      <th>song_hotttnesss</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.388990</td>\n",
              "      <td>0.386740</td>\n",
              "      <td>0.406370</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.388990</td>\n",
              "      <td>0.386740</td>\n",
              "      <td>0.406370</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.388990</td>\n",
              "      <td>0.386740</td>\n",
              "      <td>0.406370</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.557339</td>\n",
              "      <td>0.614272</td>\n",
              "      <td>0.798387</td>\n",
              "      <td>0.005158</td>\n",
              "      <td>0.354516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.388990</td>\n",
              "      <td>0.386740</td>\n",
              "      <td>0.406370</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  artist_discovery artist_familiarity  ... song_currency song_hotttnesss\n",
              "                                       ...                              \n",
              "0         0.388990           0.386740  ...      0.000000        0.000000\n",
              "1         0.388990           0.386740  ...      0.000000        0.000000\n",
              "2         0.388990           0.386740  ...      0.000000        0.000000\n",
              "3         0.557339           0.614272  ...      0.005158        0.354516\n",
              "4         0.388990           0.386740  ...      0.000000        0.000000\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>artist_discovery_rank</th>\n",
              "      <th>artist_familiarity_rank</th>\n",
              "      <th>artist_hotttnesss_rank</th>\n",
              "      <th>song_currency_rank</th>\n",
              "      <th>song_hotttnesss_rank</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2635.0</td>\n",
              "      <td>2544.0</td>\n",
              "      <td>397.0</td>\n",
              "      <td>115691.0</td>\n",
              "      <td>67609.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  artist_discovery_rank  ... song_hotttnesss_rank\n",
              "                         ...                     \n",
              "0                   NaN  ...                  NaN\n",
              "1                   NaN  ...                  NaN\n",
              "2                   NaN  ...                  NaN\n",
              "3                2635.0  ...              67609.0\n",
              "4                   NaN  ...                  NaN\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}